# 关于利用神经网络的二进制文件漏洞检测方法

​		我选择的论文为**Neural Network-based Graph Embedding for Cross-Platform Binary Code Similarity Detection**, 该论文旨在介绍一种叫做**Gemini**的新方法，来处理跨平台二进制文件的相似性检测。 相比之前的将二进制文件转化为ACFG然后进行二分图匹配的算法， 这个方法将ACFG利用孪生神经网络进行嵌入，通过预训练和之后的再训练来面对不同的应用场景并且提高漏洞文件检测的准确率和训练效率。

​		该论文先介绍了在**Gemini**之前的匹配方法以及其他基于神经网络的算法**Genius**，然后分析得出效率慢的原因是因为之前的匹配方法都需要*时间复杂度较高的图的匹配算法*，因而引出了新的算法，利用神经网络来将ACFG进行嵌入，而且相比于基于分类器的**Genius**算法，**Gemini**算法采用嵌套了**Structure2vec**的孪生神经网络，训练的目的是判断两个输入$（g,g'）$的相似度$\pi(g,g')$，令$\pi(g,g')=1$表示$(g,g')$为相似的，相反当$\pi(g,g')=-1$时代表$(g, g')$为不相似的, 经过神经网络训练的输出为$\phi(g)$, 代表$g$的嵌入向量。**Gemini**算法优化的目标是最小化$$\sum_{i=1}^{K}(Sim(g_i,g_i')-y_i)^2$$。在该论文中。 $$Sim(g_0, g_1)=cos(g_0,g_1)=\frac{<\phi(g_0), \phi(g_1)>}{||\phi(g_0)|| ||\phi(g_1)||}$$。 为了达到最优化目的, **Gemini**采用了如下的方法。

​		定义$g=<V,E>$来表示ACFG，$V, E$分别表示对应的点集和边集，用$x_v$来代表图中的每一个节点$v$的附加属性。然后嵌入神经网络首先计算每个节点的$p$维向量$\mu_v$,然后再根据$\mu_v$来计算出$\mu_g$，其中$\mu_g=A_{v\in V}(\mu_v)$在该论文中，$A=\sum$, $\mu_g=\sum_{\mu\in V}(\mu_v)$。关于$\mu_v$的计算, 这里借鉴了**Structure2vec**的做法, 将每一个节点的初始值$\mu_v^{0}$设置为$0$,然后每一轮按照如下计算新的$\mu_v$,$\mu_v^{t+1}=F(x_v,\sum_{u\in \mathcal{N}(v)}\mu_u^{t}),\forall \mathcal{v}\in \mathcal{V}$。$\mathcal{F}$的定义为$\mathcal{F}(x_v,\sum_{u\in \mathcal{N}(v)}\mu_u)=tanh(W1x_v+\sigma(\sum_{u\in \mathcal{N}(v)}))$ , $\sigma$定义为$\sigma(l)=P_1\times ReLU(P_2\times ... ReLU(P_nl))$, 其中$P_i$是$p\times p$的矩阵，$n$为嵌入深度, $ReLU(x)=max\{0,x\}$  

​		算法的基本流程如下:

1. **Input**: $ACFG g = <\mathcal{V},\mathcal{E},\hat{x}>$
2. Initialize $\mu_v^0=\hat{0}$,for all $v\in \mathcal{V}$  
3. **for** t = 1 to T **do**
4. ​     **for** $v\in \mathcal{V}$ **do**
5. ​          $l_v=\sum_{u\in \mathcal{N}(v)}\mu_u^{t-1}$  
6. ​          $\mu_v^t=tanh(W_1x_v+\sigma(l_v))$
7. ​       **end for**
8. **end for**{fixed point equation update}
9. **return** $\phi(g):=W_2(\sum_{v\in \mathcal{V}}\mu_v^T)$ 

在此嵌入网络的基础上, 该论文利用了随机梯度下降法来训练参数$W_1,P_1,...,P_n,W_2$  

​		**Gemini**所采用的神经网络模型具有数据集易于构造和训练效率高等优点。为了解决数据集的问题，**Gemini**的正数据集是利用相同源程序在不同版本和优化选项的编译器下编译产生的二进制文件，而负数据集是利用不同源程序在不同版本和优化选项的编译器下编译产生的二进制文件， 通过这种方式可以方便的得到**Gemini**的预训练训练集，以此方法进行预训练之后，当**Gemini**需要解决实际场景的问题时，训练的数据集需要由专家收集给出，并进行再训练。与之前基于图匹配和codebook的**Genius**相比，**Gemini**的训练速度更快，并且准确率更高，而且因为神经网络结构的不同，**Gemini**可以提供更快的离线训练，与之前的方法相比，**Gemini**在效率和准确度方面取得了不错的进展。

​		在实验验证部分，本论文将**Gemini**与**BGM**, **Genius**作为基准进行比较, 并且将数据集分为**Dataset I**用来训练神经网络和评估预训练模型的准确度, 并将数据详细的分为**Training**, **Validation**,和**Testing**, 其中由相同源码编译出的二进制文件会被放到相同的集合中来估计**Gemini**对未见过的样本的预测准确度 , **Dataset II**，用来评估对于特定任务模型的表现, **Dataset III**, 用来测试该算法的效率, **Dataset IV**为漏洞数据集来进行神经网络的案例研究。并对每个参数的选择进行了实验判断。

​		对于**Gemini**的准确性测试, 作者对于**Dataset I**中的**testing part**中的每一个$g$, 随机从Dataset I中的testing part中选择$g_1,g_2$使得$\pi(g,g_1)=1,\pi(g,g_2)=-1$, 通过$26265$对ACFG, 最终得到测试结果**Gemini**优于**BGM**和**Genius**, 然后为了比较**Gemin**、**BGM**、**Genius**在不同大小的ACFG上的表现, 作者分别测试了这三种方法在较大size的ACFG和较小size的ACFG的表现，最终得出**Gemini**在大数据和小数据测试集上准确度都优于另外两种方法。

​		对于**Gemini**的效率测试, 作者分别比较了ACFG生成的时间, ACFG的特征提取生成嵌入向量的时间, 以及前两个任务的加和，并且分别测试比较了**Genius**的单线程、多线程，**Gemini**的CPU运行和GPU运行的效率。得出结论ACFG解析在Block+O和仅Block情况下效率相差不多, 但Block+O+B效率远低于前两种情况，嵌入向量多线程**Genius**在ACFG size较小的情况下效率低于单线程**Genius**, 但是随着ACGF size的增大, 多线程的Genius 效率明显优于单线程Genius, 但在给出的ACFG size中Gemini的CPU GPU运行效率都远高于Genius， 这证明了Gemini的高效率。

​		为了测试嵌入向量的效果, 作者将高维的嵌入向量投影到二维的平面上， 由图可知不同函数的分散程度较远， 证明了**Gemini**模型嵌入过程的有效性。

​		最后是**Gemini**在实际生产中的再训练准确度测试, 作者选用了**Dataset II**, 然后从Dataset IV中选取2个漏洞, 并且对于每一个漏洞来对Dataset I中的函数进行匹配。作者采用了用Dataset I预训练过的模型来对每一个漏洞进行再训练，得出结果Gemini对top 50的高危漏洞的预测准确率高达$80\%$, 而其他方法只有$20\%$到$50\%$， 以此来证明Gemini再训练之后的准确率。

​		阅读该论文之后，我认为**Gemini**可以进一步优化, 比如计算$\mu_g$时的$A$函数，可以采用更复杂的函数，而不是简单的求和函数，求和函数可能会损失$g$的一些特征。在实验验证中, 最后只选取两个漏洞来进行比较可能显得较少, 而且针对top 50的漏洞可能对其他漏洞的检测存在检测不严谨的问题, 可以增加其他新发现漏洞的比对来证明Gemini对于新增的漏洞的检测的有效性。

​		

